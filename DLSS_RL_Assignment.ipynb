{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLSS RL Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0LNqmFS049t"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nihalgeorge01/DLSS_RL/blob/main/DLSS_RL_Assignment.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqX8zONPzfGa"
      },
      "source": [
        "# Black Hole\n",
        "### This game is described using a 10 X 10 grid :\n",
        ">   \n",
        "\\_ \\_ \\_ \\_ \\_ \\_ \\_ \\_ \\_ H  \n",
        "\\_ \\_ \\_ \\_ \\_ \\_ \\_ H \\_ \\_  \n",
        "\\_ \\_ \\_ \\_ \\_ H \\_ \\_ \\_ \\_  \n",
        "\\_ \\_ \\_ H \\_ \\_ \\_ \\_ \\_ \\_  \n",
        "\\_ H \\_ \\_ \\_ \\_ \\_ \\_ \\_ \\_  \n",
        "\\_ \\_ \\_ \\_ \\_ \\_ \\_ \\_ \\_ H  \n",
        "\\_ \\_ \\_ \\_ \\_ \\_ \\_ H \\_ \\_  \n",
        "\\_ \\_ \\_ \\_ \\_ H \\_ \\_ \\_ \\_  \n",
        "\\_ \\_ \\_ H \\_ \\_ \\_ \\_ \\_ \\_  \n",
        "G H \\_ \\_ \\_ \\_ \\_ \\_ \\_ \\_  \n",
        "\n",
        "\\_ : Safe path  \n",
        "H : Black Hole, avoid falling  \n",
        "G: Goal, target to reach  \n",
        "\n",
        "Holes will continuously move 1 step left during each timestep.  \n",
        "Your goal is to reach G.  \n",
        "You fall into the hole only if your position coincides with the hole.  \n",
        "The episode ends when you reach G or fall in H.  \n",
        "If you reach G, you win.  \n",
        "If you reach H, you lose.  \n",
        "If you reach G at a time when it coincides with H, you lose.  \n",
        "## Reward Scheme \n",
        "- 1 if you reach G  \n",
        "- -1 if you fall in H  \n",
        "- 0 otherwise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV64yW7Tl1Tj"
      },
      "source": [
        "# **DO NOT EDIT THE CELL BELOW**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42AI1ItvI_Ho"
      },
      "source": [
        "import random\n",
        "import sys\n",
        "import copy\n",
        "class BlackHole:\n",
        "  class action:\n",
        "    def __init__(self):\n",
        "      self.total_actions = 5\n",
        "      self.dtype = type(self.total_actions)\n",
        "      self.__out=sys.stdout\n",
        "    \n",
        "    def random_action(self):\n",
        "      act = random.randint(1,5)\n",
        "      return act\n",
        "\n",
        "    def show_actions(self):\n",
        "      actions= \"1->Up, 2->Right, 3->Down, 4->Left 5->Stay\"\n",
        "      self.__out.write(actions)\n",
        "    \n",
        "  class observation:\n",
        "    def __init__(self):\n",
        "      self.total_observations = 1000\n",
        "      self.dtype = type(self.total_observations)\n",
        "      self.__lst =[x for x in range(1,1000) if x%100 is not 0]\n",
        "\n",
        "    def random(self):\n",
        "      obs = random.sample(self.__lst,1)[0]\n",
        "      return obs\n",
        "  def __init__(self):\n",
        "    self.observation_space = self.observation()\n",
        "    self.__map=['_________H',\n",
        "                '_______H__',\n",
        "                '_____H____',\n",
        "                '___H______',\n",
        "                '_H________',\n",
        "                '_________H',\n",
        "                '_______H__',\n",
        "                '_____H____',\n",
        "                '___H______',\n",
        "                'GH________']\n",
        "    self.action_space = self.action()\n",
        "    self.__x = None\n",
        "    self.__y = None\n",
        "    self.__state = None\n",
        "    self.__out = sys.stdout\n",
        "    self.__action = None\n",
        "    self.__action_dict = {1:'Up',2:'Right',3:'Down',4:'Left',5:'Stay'}\n",
        "    self.__done = False\n",
        "    self.__h = None\n",
        "\n",
        "  def reset(self):\n",
        "    self.__y = 0\n",
        "    self.__h = 9\n",
        "    self.__adjust_h()\n",
        "    self.__x = random.randint(0,4)\n",
        "    self.current_state()\n",
        "    self.__action = None\n",
        "    self.__done = False\n",
        "    return self.__state\n",
        "\n",
        "  def __adjust_h(self):\n",
        "    for i in  range(len(self.__map)):\n",
        "      if i==9 and self.__map[i].count('_')==9:\n",
        "        self.__map[9] = self.__map[9][:9]\n",
        "      self.__map[i] = ''.join(i for i in self.__map[i] if i is not 'H')\n",
        "      index = self.__h-2*i \n",
        "      index  = index + (index<0 and index>-10)*10 + (index<-10)*20 \n",
        "      self.__map[i] = self.__map[i][:index] + 'H' + self.__map[i][index:]\n",
        "    if self.__h == 8:\n",
        "      self.__map[9] = ''.join(i for i in self.__map[9] if i is not 'H')+'_'\n",
        "  \n",
        "  def current_state(self):\n",
        "    if self.__y is not None:\n",
        "     self.__state = (9-self.__h)*100+self.__y*10+self.__x+1\n",
        "    return self.__state\n",
        "\n",
        "  def take_step(self,action):\n",
        "    if self.__done == False :\n",
        "      reward = 0.0\n",
        "      if action == 1:\n",
        "        if self.__y-1>=0:\n",
        "          self.__y-=1\n",
        "        self.__action = action\n",
        "      elif action == 3:\n",
        "        if self.__y+1<=9:\n",
        "          self.__y+=1\n",
        "        self.__action = action\n",
        "      elif action == 2:\n",
        "        if self.__x+1<=9:\n",
        "          self.__x+=1\n",
        "        self.__action = action\n",
        "      elif action == 4:\n",
        "        if self.__x-1>=0:\n",
        "          self.__x-=1\n",
        "        self.__action = action\n",
        "      elif action == 5:\n",
        "        self.__action = action\n",
        "      else:\n",
        "        self.__out.write(\"Enter a valid action.\")\n",
        "        return\n",
        "      self.__h  = self.__h -1 + (self.__h-1<0)*10\n",
        "      self.__adjust_h()\n",
        "      self.current_state()\n",
        "      if self.__map[self.__y][self.__x]=='G' :\n",
        "        reward=1.0\n",
        "        self.__done= True\n",
        "        if self.__h ==8:\n",
        "          reward = -1.0\n",
        "          self.__done = True\n",
        "      if self.__map[self.__y][self.__x]=='H':\n",
        "        reward = -1.0\n",
        "        self.__done = True\n",
        "      return self.__state,reward,self.__done\n",
        "    else :\n",
        "      self.__out.write(\"\\n\\033[38;5;11mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True\\033[0;0m\")\n",
        "\n",
        "  def show(self):\n",
        "    if self.__state is not None:\n",
        "      map = copy.deepcopy(self.__map)\n",
        "      val = map[self.__y][self.__x]\n",
        "      map[self.__y] = map[self.__y][:self.__x] + 'P' +map[self.__y][self.__x+1:]\n",
        "      map = self.__add_colour_h(map)\n",
        "      map[-1]=map[-1].replace('G',\"\\033[38;5;12mG\\033[0;0m\")\n",
        "      map[self.__y] = map[self.__y].replace('P',f'\\033[48;5;9m{val}\\033[0;0m')\n",
        "      if self.__action is not None:\n",
        "        self.__out.write('\\n'+self.__action_dict[self.__action])\n",
        "      self.__out.write(\"\\n+----------+\")\n",
        "      for i in map:\n",
        "        self.__out.write('\\n|'+i+'|')\n",
        "      self.__out.write(\"\\n+----------+\")\n",
        "      if val =='H':\n",
        "        self.__out.write(\"\\nTRY AGAIN.......You fell in Black Hole!!!\")\n",
        "      if val =='G':\n",
        "        if self.__h is not 8 : \n",
        "          self.__out.write(\"\\nGG!!\")\n",
        "        else :\n",
        "          self.__out.write(\"\\nYou reached but fell in Black Hole\")\n",
        "      self.__out.write(\"\\n\")\n",
        "    else :\n",
        "      self.__out.write('NONE')\n",
        "\n",
        "  def __add_colour_h(self,map):\n",
        "    for i in range(len(map)):\n",
        "      map[i]=map[i].replace('H','\\033[48;5;16mH\\033[0;0m')\n",
        "    if self.__h == 8:\n",
        "      map[9] = map[9].replace('G','\\033[48;5;16mG\\033[0;0m')\n",
        "    return map\n",
        "\n",
        "  def set_state(self,state):\n",
        "    if state>1000 or state<1:\n",
        "      self.__out.write(\"Enter a valid state.\")\n",
        "      return\n",
        "    self.__state = state\n",
        "    self.__h = 9 - (state-1)//100\n",
        "    self.__y = ((state-1)%100)//10\n",
        "    self.__x = ((state-1)%100)%10\n",
        "    self.__adjust_h()\n",
        "    if self.__map[self.__y][self.__x]=='_':\n",
        "      self.__done = False\n",
        "    else: \n",
        "      self.__done = True\n",
        "    self.__action = None"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj_sx_AH2Sum"
      },
      "source": [
        "# Environment methods and attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz4_-7xu2mL2"
      },
      "source": [
        "env = BlackHole() #Creating object of BlackHole class"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ocX7o8B2tj1",
        "outputId": "0ca83d19-cb4b-4e65-e572-6da375fa4ff4"
      },
      "source": [
        "print(env.observation_space.total_observations) #Total observations in observation space\n",
        "print(env.observation_space.random()) # Random observation from observation space"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE3kSOaN3tNr",
        "outputId": "17cbd645-08b1-4455-8e22-49ee2b6231a9"
      },
      "source": [
        "print(env.action_space.total_actions) #Total actions in action space\n",
        "print(env.action_space.random_action()) #Returns random action from action space\n",
        "env.action_space.show_actions() #Prints details about actions in action space"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "4\n",
            "1->Up, 2->Right, 3->Down, 4->Left 5->Stay"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mm8C4zO3uyg",
        "outputId": "417b9db6-e638-468c-b787-8758c11a0bbd"
      },
      "source": [
        "print(env.current_state()) #No state is initialized"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkCeJnMS3xud",
        "outputId": "02d1b317-75c0-41c3-ece4-c93609b0bb2b"
      },
      "source": [
        "env.reset() #initializes game and you are spawned at one of first five blocks\n",
        "env.show() #prints observation\n",
        "print(env.current_state())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "+----------+\n",
            "|_\u001b[48;5;9m_\u001b[0;0m_______\u001b[48;5;16mH\u001b[0;0m|\n",
            "|_______\u001b[48;5;16mH\u001b[0;0m__|\n",
            "|_____\u001b[48;5;16mH\u001b[0;0m____|\n",
            "|___\u001b[48;5;16mH\u001b[0;0m______|\n",
            "|_\u001b[48;5;16mH\u001b[0;0m________|\n",
            "|_________\u001b[48;5;16mH\u001b[0;0m|\n",
            "|_______\u001b[48;5;16mH\u001b[0;0m__|\n",
            "|_____\u001b[48;5;16mH\u001b[0;0m____|\n",
            "|___\u001b[48;5;16mH\u001b[0;0m______|\n",
            "|\u001b[38;5;12mG\u001b[0;0m\u001b[48;5;16mH\u001b[0;0m________|\n",
            "+----------+\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV1rFKPt45fL",
        "outputId": "506baeb0-73ed-440b-c137-861bae8e71d8"
      },
      "source": [
        "env.set_state(env.observation_space.random()) #state of environment is changed to state specified\n",
        "env.show() \n",
        "print(env.current_state())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "+----------+\n",
            "|___\u001b[48;5;16mH\u001b[0;0m______|\n",
            "|_\u001b[48;5;16mH\u001b[0;0m________|\n",
            "|_________\u001b[48;5;16mH\u001b[0;0m|\n",
            "|_______\u001b[48;5;16mH\u001b[0;0m__|\n",
            "|_____\u001b[48;5;16mH\u001b[0;0m____|\n",
            "|___\u001b[48;5;16mH\u001b[0;0m____\u001b[48;5;9m_\u001b[0;0m_|\n",
            "|_\u001b[48;5;16mH\u001b[0;0m________|\n",
            "|_________\u001b[48;5;16mH\u001b[0;0m|\n",
            "|_______\u001b[48;5;16mH\u001b[0;0m__|\n",
            "|\u001b[38;5;12mG\u001b[0;0m____\u001b[48;5;16mH\u001b[0;0m____|\n",
            "+----------+\n",
            "659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6-bR6VW4IfZ"
      },
      "source": [
        "### env.take_step( ) returns THREE values only -- state, reward and done (episode completed or not) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTujgWrb4HS_",
        "outputId": "2f54ee36-f059-482d-9f22-392a88a5a74d"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "env.reset()\n",
        "done = False\n",
        "while True:\n",
        "  env.show()\n",
        "  clear_output(wait=True)\n",
        "  sleep(1.0)\n",
        "  if done: \n",
        "    break\n",
        "  action = env.action_space.random_action()\n",
        "  state,reward,done = env.take_step(action)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Stay\n",
            "+----------+\n",
            "|___\u001b[48;5;9mH\u001b[0;0m______|\n",
            "|_\u001b[48;5;16mH\u001b[0;0m________|\n",
            "|_________\u001b[48;5;16mH\u001b[0;0m|\n",
            "|_______\u001b[48;5;16mH\u001b[0;0m__|\n",
            "|_____\u001b[48;5;16mH\u001b[0;0m____|\n",
            "|___\u001b[48;5;16mH\u001b[0;0m______|\n",
            "|_\u001b[48;5;16mH\u001b[0;0m________|\n",
            "|_________\u001b[48;5;16mH\u001b[0;0m|\n",
            "|_______\u001b[48;5;16mH\u001b[0;0m__|\n",
            "|\u001b[38;5;12mG\u001b[0;0m____\u001b[48;5;16mH\u001b[0;0m____|\n",
            "+----------+\n",
            "TRY AGAIN.......You fell in Black Hole!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0a7d6IHxRWQ",
        "outputId": "0923a43b-805b-4890-fc16-5a62964aea9b"
      },
      "source": [
        "state,reward,done"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(604, -1.0, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohra4kBeYvhw"
      },
      "source": [
        "## **Task**\n",
        "### Now you are familiar with BlackHole environment. You have to implement Q-learning on this custom environment. Remember you are not allowed to do any changes in BlackHole class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epKaPqhTo0yt",
        "outputId": "41a42363-7d5b-4684-9831-8b96619c561c"
      },
      "source": [
        "env.reset()\n",
        "# env.observation_space.random()\n",
        "env.take_step(env.action_space.random_action())\n",
        "env.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Up\n",
            "+----------+\n",
            "|___\u001b[48;5;9m_\u001b[0;0m____\u001b[48;5;16mH\u001b[0;0m_|\n",
            "|______\u001b[48;5;16mH\u001b[0;0m___|\n",
            "|____\u001b[48;5;16mH\u001b[0;0m_____|\n",
            "|__\u001b[48;5;16mH\u001b[0;0m_______|\n",
            "|\u001b[48;5;16mH\u001b[0;0m_________|\n",
            "|________\u001b[48;5;16mH\u001b[0;0m_|\n",
            "|______\u001b[48;5;16mH\u001b[0;0m___|\n",
            "|____\u001b[48;5;16mH\u001b[0;0m_____|\n",
            "|__\u001b[48;5;16mH\u001b[0;0m_______|\n",
            "|\u001b[48;5;16m\u001b[38;5;12mG\u001b[0;0m\u001b[0;0m_________|\n",
            "+----------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRP6ITZb2uyQ",
        "outputId": "c6634b67-87e9-415a-af90-aa71692f0243"
      },
      "source": [
        "# action = env.action_space.random_action()\n",
        "# env.take_step(action)\n",
        "env.reset()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdWDu_HExv3y"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "q_table = np.zeros([env.observation_space.total_observations, env.action_space.total_actions])\n",
        "print(q_table)\n",
        "(alpha, gamma, episodes, epsilon) = (0.6, 0.9, 10, 0.4)\n",
        "total_epochs =0\n",
        "total_penalty = 0\n",
        "illegal_episode =[]\n",
        "for i in range(episodes):\n",
        "  state = env.reset()\n",
        "  epochs = 0\n",
        "  penalty, reward_tot = 0, 0  \n",
        "  illegal =0\n",
        "  \n",
        "  done = False \n",
        "  while not done:\n",
        "    rand = random.uniform(0,1)\n",
        "    if rand < epsilon:\n",
        "      action = env.action_space.random_action()\n",
        "    if rand >= epsilon:\n",
        "      action = np.argmax(q_table[state])+1\n",
        "    # import pdb; pdb.set_trace()\n",
        "    # new_state, reward, done = env.take_step(action)\n",
        "    new_state,reward,done = env.take_step(action)\n",
        "    if new_state == state:\n",
        "      penalty+=1\n",
        "\n",
        "    if reward == -10:\n",
        "      illegal+=1\n",
        "\n",
        "    epochs += 1\n",
        "\n",
        "    #Q_cal = Reward + gamma*max{a}(Q(s',.))\n",
        "    #new_q = oldq + aplha(Q_cal - oldq) = (1-alpha)oldq + alpha(Q_cal)\n",
        "          \n",
        "    # import pdb; pdb.set_trace()\n",
        "    oldq = q_table[state, action-1]\n",
        "    new_state_max = np.max(q_table[new_state]) \n",
        "    newq = (1 - alpha) * oldq + alpha * (reward + gamma * new_state_max)\n",
        "    q_table[state, action-1] = newq\n",
        "    print(q_table)\n",
        "    state = new_state\n",
        "    epochs+=1\n",
        "  illegal_episode.append(illegal)\n",
        "  total_penalty+=penalty\n",
        "  total_epochs+=epochs\n",
        "\n",
        "total_penalty/=episodes\n",
        "total_epochs/=episodes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjyGADEqxwqG",
        "outputId": "9688e5ba-6198-4f3c-9022-a4edf57241af"
      },
      "source": [
        "state = env.reset()\n",
        "epochs = 0\n",
        "penalty, reward = 0, 0  \n",
        "frames = []\n",
        "done = False\n",
        "while not done:\n",
        "    action = np.argmax(q_table[state,:])+1\n",
        "    new_state, reward, done= env.take_step(action)\n",
        "    if new_state == state:\n",
        "      penalty+=1\n",
        "    state = new_state\n",
        "\n",
        "    frames.append({\n",
        "        # 'frame': env.render(mode='ansi'), \n",
        "        'state': state, 'action': action, 'reward': reward})\n",
        "    epochs += 1\n",
        "print(\"Timesteps taken: {}\".format(epochs))\n",
        "print(\"Penalties incurred: {}\".format(penalty))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Timesteps taken: 43\n",
            "Penalties incurred: 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}